import { ExtractFn, ArrayFn, AtLeastOneElement, AbstractQuery } from '@directus/data';
import { GeoJSONGeometry } from 'wellknown';
import { ReadableStream } from 'node:stream/web';

/**
 * Used pass a single value.
 */
interface ValueNode {
    type: 'value';
    parameterIndex: number;
}
/**
 * Used pass an arbitrary amount of values.
 */
interface ValuesNode {
    type: 'values';
    parameterIndexes: number[];
}
/**
 * An actual vendor specific SQL statement with its parameters.
 * @example
 * ```
 * {
 * 		statement: 'SELECT * FROM "articles" WHERE "articles"."id" = $1;',
 * 		values: [99],
 * }
 * ```
 */
interface ParameterizedSqlStatement {
    statement: string;
    parameters: ParameterTypes[];
}
type ParameterTypes = string | boolean | number | GeoJSONGeometry;

interface AbstractSqlQueryColumn {
    table: string;
    column: string;
}

/**
 * Used to apply a function to a column.
 * Currently we support various EXTRACT functions to extract specific parts out of a data/time value.
 */
interface AbstractSqlQuerySelectFnNode extends AbstractSqlQueryColumn {
    type: 'fn';
    /**
     * A list of supported functions. Those are the same as the abstract query.
     */
    fn: ExtractFn | ArrayFn;
    arguments?: ValuesNode;
    as?: string;
}

/**
 * Used to select a specific column from a table.
 */
interface AbstractSqlQuerySelectPrimitiveNode extends AbstractSqlQueryColumn {
    type: 'primitive';
    as?: string;
}

type AbstractSqlQuerySelectNode = AbstractSqlQuerySelectPrimitiveNode | AbstractSqlQuerySelectFnNode;

/**
 * Condition to filter rows where two columns of different tables are equal.
 * Mainly used for JOINs.
 */
interface SqlConditionFieldNode {
    type: 'condition-field';
    operation: 'eq';
    target: AbstractSqlQuerySelectNode;
    compareTo: AbstractSqlQuerySelectNode;
}

/**
 * Used to retrieve a set of data, where the column in question stores a geographic value which intersects with another given geographic value.
 * Here, the two types `condition-geo` and `condition-geo-bbox` from @directus/data are combined into one type,
 * because the compare value is the same for both types - it's the reference to the actual value stored in the list of parameters.
 * That also why the operations got merged together.
 */
interface SqlConditionGeoNode {
    type: 'condition-geo';
    target: AbstractSqlQuerySelectNode;
    /**
     * The operation to apply. Get only those rows where the targeting column
     * - `intersects`: intersects with the given geo value
     * - `intersects_bbox`: intersects with a given bounding box
     */
    operation: 'intersects' | 'intersects_bbox';
    compareTo: ValueNode;
}

/**
 * Filter rows where a numeric column is equal, greater than, less than, etc. other given number.
 */
interface SqlConditionNumberNode {
    type: 'condition-number';
    target: AbstractSqlQuerySelectNode;
    operation: 'eq' | 'lt' | 'lte' | 'gt' | 'gte';
    compareTo: ValueNode;
}

interface SqlConditionSetNode {
    type: 'condition-set';
    operation: 'in';
    target: AbstractSqlQuerySelectNode;
    compareTo: ValuesNode;
}

/**
 * Condition to filter rows where a string column value contains, starts with, ends with, or is equal to another given string.
 */
interface SqlConditionStringNode {
    type: 'condition-string';
    target: AbstractSqlQuerySelectNode;
    operation: 'contains' | 'starts_with' | 'ends_with' | 'eq';
    compareTo: ValueNode;
}

/**
 * Condition to filter rows.
 * Various condition types are supported, each depending on a specific datatype.
 * The condition can also be negated on this level.
 */
interface AbstractSqlQueryConditionNode {
    type: 'condition';
    condition: SqlConditionStringNode | SqlConditionNumberNode | SqlConditionGeoNode | SqlConditionSetNode | SqlConditionFieldNode;
    negate: boolean;
}

/**
 * A wrapper to add multiple conditions at once.
 */
interface AbstractSqlQueryLogicalNode {
    type: 'logical';
    operator: 'and' | 'or';
    negate: boolean;
    childNodes: AtLeastOneElement<AbstractSqlQueryConditionNode | AbstractSqlQueryLogicalNode>;
}

/**
 * Used to join another table, regardless of the type of relation.
 */
interface AbstractSqlQueryJoinNode {
    type: 'join';
    table: string;
    on: AbstractSqlQueryConditionNode | AbstractSqlQueryLogicalNode;
    as: string;
}

interface AbstractSqlQueryOrderNode {
    type: 'order';
    orderBy: AbstractSqlQuerySelectNode;
    direction: 'ASC' | 'DESC';
}

type AbstractSqlQueryWhereNode = AbstractSqlQueryConditionNode | AbstractSqlQueryLogicalNode;

interface AbstractSqlClauses {
    select: AbstractSqlQuerySelectNode[];
    from: string;
    joins?: AbstractSqlQueryJoinNode[];
    where?: AbstractSqlQueryWhereNode;
    limit?: ValueNode;
    offset?: ValueNode;
    order?: AbstractSqlQueryOrderNode[];
}

/**
 * A set of types which form the abstract SQL query.
 * It's still neutral to concrete SQL dialects and databases but provides to SQL drivers with a query type that they can more easy work with.
 *
 * How the abstract SQL query types differ from the abstract query.
 * - In the abstract query the user input values are put directly within the query directly.
 * The abstract SQL however stores the user input values in a list of parameters, so that the SQL driver always perform parameterized queries.
 * That way we prevent SQL injection.
 * Moving the user input values into a list of parameters and replace the input value with the index of the value from the list, is a big part of the converter.
 * - Instead of a wrapper for negation, here the negation is a property on the type.
 * So the abstract SQL does not have a node of type 'negate' but instead the nodes have a property called 'negate'.
 *
 * @module
 */

/**
 * This is an abstract SQL query which can be passed to all SQL drivers.
 *
 * @example
 * The following query gets the title of all articles and limits the result to 25 rows.
 * ```ts
 * const query: SqlStatement = {
 * 	clauses: {
 *     select: [title],
 *     from: 'articles',
 *     limit: 0, // this is the index of the parameter
 *  },
 * 	parameters: [25],
 * };
 * ```
 */
interface AbstractSqlQuery {
    clauses: AbstractSqlClauses;
    parameters: ParameterTypes[];
}
type SubQuery = (rootRow: Record<string, unknown>) => {
    rootQuery: AbstractSqlQuery;
    subQueries: SubQuery[];
    aliasMapping: AliasMapping;
};
type AliasMapping = ({
    type: 'nested';
    alias: string;
    children: AliasMapping;
} | {
    type: 'root';
    alias: string;
    column: string;
} | {
    type: 'sub';
    alias: string;
    index: number;
})[];
interface ConverterResult {
    rootQuery: AbstractSqlQuery;
    subQueries: SubQuery[];
    aliasMapping: AliasMapping;
}

/**
 * Converts an abstract query to the abstract SQL query ({@link AbstractSqlClauses}).
 * This converter is used as the first action within the SQL drivers.
 *
 * @module
 */

/**
 * Here the abstract query gets converted into the abstract SQL query.
 * It calls all related conversion functions and takes care of the parameter index.
 * This process, is also part of the ORM since here the aliases get generated and the mapping of aliases to the original fields is created.
 *
 * @param abstractQuery the abstract query to convert
 * @returns the abstract sql query
 */
declare const convertQuery: (abstractQuery: AbstractQuery) => ConverterResult;

/**
 * Appends a pseudo-random value to the end of a given identifier to make sure it's unique within the
 * context of the current query. The generated identifier is used as an alias to select columns and to join tables.
 *
 * @remarks
 * The uniqueness of a table or column within the schema is not enough for us, since f.e. the same table can be joined multiple times
 * and only with some randomness added, we can ensure that the ORM does the nesting correctly.
 *
 * @todo OracleDB has a max length of 30 characters for identifiers. Is this the right spot to
 * ensure that, or should that be on the DB level?
 */
declare const createUniqueAlias: (identifier: string) => string;

/**
 * This logic handles o2m relational nodes which can be seen as default implementation/behavior for all SQL drivers.
 *
 * @param rootStream the stream of the root query
 * @param subQueries the sub query generators that generate queries to query relational data
 * @param aliasMapping the mapping that maps the result structure to root rows and sub query results
 * @param queryDatabase a function which is defined in the drivers which queries the database
 * @returns the final stream which contains the mapped root query and sub query results
 */
declare function getMappedQueriesStream(rootStream: ReadableStream<Record<string, unknown>>, subQueries: SubQuery[], aliasMapping: AliasMapping, queryDatabase: (query: AbstractSqlQuery) => Promise<ReadableStream<Record<string, unknown>>>): ReadableStream<Record<string, unknown>>;

/**
 * This unit takes care of transforming the response from the database into into a nested JSON object.
 *
 * @remarks
 * A SQL database returns the result as a two dimensional table, where the actual data are the rows and the columns specify the fields.
 * Such result is a flat Javascript object but we want to return a nested object which maps the realtionships form the database into a nested structure of an object.
 *
 * @example
 * Let's say we have the two collections articles and authors and we want to query all articles with all data about the author as well.
 * This would be the SQL query:
 *
 * ```sql
 * select * from articles join authors on authors.id = articles.author;
 * ```
 * The following is a chunk from an example response from the database:
 * ```json
 * {
 *   "id": 1,
 *   "status": "published",
 *   "author": 1,
 *   "title": "some news",
 *   "name": "jan"
 * },
 * ```
 * The first four rows were stored in the articles table, the last two in the authors table.
 * But what we want to return to the user is the following:
 * ```json
 * {
 *   "id": 1,
 *   "status": "published",
 *   "title": "some news",
 *   "author": {
 *      "id": 1,
 *   	"name": "jan"
 * 		},
 * },
 * ```
 * That's what this unit is for.
 *
 * @module
 */

declare function mapResult(aliasMapping: AliasMapping, rootRow: Record<string, unknown>, subResult: Record<string, unknown>[][]): Record<string, unknown>;

/**
 * @param operation
 * @param negate
 * @returns
 */
declare function convertNumericOperators(operation: string, negate: boolean): string;

/**
 * Receives all the chunks from a stream until it's empty.
 *
 * @param readableStream the stream to be consumed
 * @returns all the data from a stream
 */
declare function readToEnd(readableStream: ReadableStream<Record<string, unknown>>): Promise<Record<string, unknown>[]>;

export { type AbstractSqlClauses, type AbstractSqlQuery, type AbstractSqlQueryColumn, type AbstractSqlQueryConditionNode, type AbstractSqlQueryJoinNode, type AbstractSqlQueryLogicalNode, type AbstractSqlQueryOrderNode, type AbstractSqlQuerySelectFnNode, type AbstractSqlQuerySelectNode, type AbstractSqlQuerySelectPrimitiveNode, type AbstractSqlQueryWhereNode, type AliasMapping, type ConverterResult, type ParameterTypes, type ParameterizedSqlStatement, type SqlConditionFieldNode, type SqlConditionGeoNode, type SqlConditionNumberNode, type SqlConditionSetNode, type SqlConditionStringNode, type SubQuery, type ValueNode, type ValuesNode, convertNumericOperators, convertQuery, createUniqueAlias, getMappedQueriesStream, mapResult, readToEnd };
